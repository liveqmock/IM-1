job launch simple --params {"class":"org.amaze.data.file.task.FSToFSTask","srcPath":"D:/Vids/SinglePageApplicationswithjQueryorAngularJS-YouTube[viatorchbrowser.com].mp4","destPath":"D:/Sample.mp4","folder":"false"}

job launch AmazeSimple --params {"srcPath":"D:/Vids/SinglePageApplicationswithjQueryorAngularJS-YouTube[viatorchbrowser.com].mp4","destPath":"D:/Sample.mp4","folder":"false"}

module upload --name AmazeSimple --type job --file D:\SRP\AWS\Amaze\Amaze-Server\Amaze-Server-Dist\target\Amaze-Server-Dist-0.0.1-SNAPSHOT\Amaze-Server-Dist-0.0.1-SNAPSHOT\plugins\job\AmazeSimple-jar-with-dependencies.jar

module upload --name AmazeSimple --type job --file D:\SRP\AWS\Amaze\Amaze-Server\Amaze-Server-Dist\target\Amaze-Server-Dist-0.0.1-SNAPSHOT\Amaze-Server-Dist-0.0.1-SNAPSHOT\plugins\job\AmazeSimple-jar-with-dependencies.jar


============================================================================================================================================================
MR
=========================================================================================================================================================
module upload --name AmazeMR --file C:\Users\310187426\Desktop\AmazeMR-1.0.0.jar --type job
job create --definition "AmazeMR --mapper=org.amaze.server.plugins.mr.test.WordCount$TokenizerMapper --reducer=org.amaze.server.plugins.mr.test.WordCount$IntSumReducer" --name MR1 --deploy
job launch MR1 --params {"input.path":"/tmp/input","output.path":"/tmp/output"}
job destroy MR1
module delete job:AmazeMR
============================================================================================================================================================


<bean id="propertyConfigurer" class="org.springframework.beans.factory.config.PropertyPlaceholderConfigurer">
  <property name="locations">
    <list>
        <value>classpath:someprops.properties</value>
    </list>
  </property>
  <property name="ignoreResourceNotFound" value="true" />
  <property name="searchSystemEnvironment" value="true" />
  <property name="systemPropertiesModeName" value="SYSTEM_PROPERTIES_MODE_OVERRIDE" />
  
  {definition=AmazeSimple --class='org.amaze.data.file.task.FSToFSTask', name=FileSystemCopyTask, deploy=true}
job create --name FileSystemCopyTask --definition "AmazeSimple --class='org.amaze.data.file.task.FSToFSTask'" --deploy



package org.amaze.server.jobs;

import java.io.IOException;
import java.util.HashMap;
import java.util.List;
import java.util.Map;

import org.amaze.commons.api.rest.RestApiUtils;
import org.amaze.commons.converters.JsonConverter;
import org.amaze.commons.exceptions.AmazeException;
import org.amaze.db.hibernate.objects.JobDefinition;
import org.amaze.db.hibernate.objects.PropertyValue;
import org.amaze.db.hibernate.objects.PropertyValueGroup;
import org.amaze.db.hibernate.utils.HibernateSession;
import org.amaze.server.jobs.exceptions.JobBuilderException;
import org.codehaus.jackson.JsonGenerationException;
import org.codehaus.jackson.map.JsonMappingException;
import org.codehaus.jackson.map.ObjectMapper;
import org.codehaus.jettison.json.JSONObject;
import org.springframework.beans.factory.annotation.Autowired;

public class JobDeployer
{

	@Autowired
	JobCommandBuilder jobCommandBuilder;

	@Autowired
	RestApiUtils apiUtils;

	public JobCommandBuilder getCommandBuilder()
	{
		return jobCommandBuilder;
	}

	public void setCommandBuilder( JobCommandBuilder commandBuilder )
	{
		this.jobCommandBuilder = commandBuilder;
	}

	public RestApiUtils getApiUtils()
	{
		return apiUtils;
	}

	public void setApiUtils( RestApiUtils apiUtils )
	{
		this.apiUtils = apiUtils;
	}

	public void createAndDeploy( JobDefinition jobDefinition )
	{
		Map<String, String> commands = jobCommandBuilder.buildCommand( jobDefinition );
		doStreamJobDeploy( jobDefinition, commands );
	}

	private void doStreamJobDeploy( JobDefinition jobDefinition, Map<String, String> commands )
	{
		if ( !jobDefinition.getJbdNeedStreamDeploy() )
			apiUtils.post( "/jobs/definitions", commands );
		else
			apiUtils.post( "/streams/definition", commands );
		createJobNotifierStream( jobDefinition );
	}

	private void createJobNotifierStream( JobDefinition jobDefinition )
	{
		if ( jobDefinition.getJbdNotifSink() != null )
		{
			Map<String, String> commands = new HashMap<String, String>();
			commands.put( "name", jobDefinition.getJbdName() + "-notifs" );
			commands.put( "deploy", "true" );
			commands.put( "definition", "\":" + jobDefinition.getJbdName() + "-notifications > " + jobDefinition.getJbdNotifSink() + " " + getNotifSinkWithProperties( jobDefinition.getJbdNotifSinkPvgIdPropertyValueGroup() ) );
			apiUtils.post( "/streams/definitions", commands );
		}
	}

	private String getNotifSinkWithProperties( PropertyValueGroup jbdNotifSinkPvgIdPropertyValueGroup )
	{
		StringBuffer eventProperties = new StringBuffer();
		if ( jbdNotifSinkPvgIdPropertyValueGroup != null )
		{
			List<PropertyValue> propertyValues = HibernateSession.query( "from PropertyValue prv where prv.pvgId = :pvgId", "pvgId", jbdNotifSinkPvgIdPropertyValueGroup.getPgpId() );
			for ( PropertyValue eachProperty : propertyValues )
				eventProperties.append( " --" ).append( eachProperty.getPrtName() ).append( " " ).append( eachProperty.getPrvValue() != null ? eachProperty.getPrvValue() : eachProperty.getPrtIdProperty() != null ? eachProperty.getPrtIdProperty().getPrtDefault() : null );
		}
		return eventProperties.toString();
	}

	public void createAndDeploy( List<JobDefinition> jobDefinitions )
	{
		for ( JobDefinition jobDefinition : jobDefinitions )
			createAndDeploy( jobDefinition );
	}

	public void createAndDeploy( String jobDefinitionName )
	{
		Map<String, String> commands = jobCommandBuilder.buildCommand( jobDefinitionName );
		doStreamJobDeploy( ( JobDefinition ) HibernateSession.queryExpectExactlyOneRow( "from JobDefinition jbd where jbd.jbdName = :jbdName", "jbdName", jobDefinitionName ), commands );
	}

	public void createAndDeployAll()
	{
		List<Map<String, String>> commands = jobCommandBuilder.buildCommand();
		for ( Map<String, String> eachJobDefinitionCommand : commands )
			doStreamJobDeploy( ( JobDefinition ) HibernateSession.queryExpectExactlyOneRow( "from JobDefinition jbd where jbd.jbdName = :jbdName", "jbdName", eachJobDefinitionCommand.get( "name" ) ), eachJobDefinitionCommand );
	}

	public void deploy( JobDefinition jobDefinition )
	{
		apiUtils.post( "/jobs/deployments" + jobDefinition.getJbdName(), null );
	}

	public void deploy( String jobDefinitionName )
	{
		apiUtils.post( "/jobs/deployments/" + jobDefinitionName, null );
	}

	public void unDeploy( JobDefinition jobDefinition )
	{
		apiUtils.delete( "/jobs/deployments/" + jobDefinition.getJbdName() );
	}

	public void unDeploy( String jobDefinitionName )
	{
		apiUtils.delete( "/jobs/deployments/" + jobDefinitionName );
	}

	public void unDeployAll()
	{
		apiUtils.delete( "/jobs/deployments/" );
	}

	public String getJob( JobDefinition jobDefinition )
	{
		return apiUtils.get( "/jobs/deployments/" + jobDefinition.getJbdName() );
	}

	public String getJob( String jobDefinitionName )
	{
		return apiUtils.get( "/jobs/deployments/" + jobDefinitionName );
	}

	public String getJobAll()
	{
		return apiUtils.get( "/jobs/deployments/" );
	}

	public String launchJob( String jobName, Map<String, String> params )
	{
		String paramValue;
		try
		{
			ObjectMapper jsonMapper = new ObjectMapper();
			paramValue = jsonMapper.writeValueAsString( params );
		}catch( IOException e ){
			throw new JobBuilderException( e );
		}
		params.clear();
		params.put( "jobParameters", paramValue );
		return apiUtils.post( "/jobs/executions?jobname=" + jobName, params );
	}

}
